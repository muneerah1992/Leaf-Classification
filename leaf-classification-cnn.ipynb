{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout\n",
    "# from keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import itertools, time, datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Datasets/Dataset1_Training.csv')\n",
    "test = pd.read_csv('Datasets/Dataset1_Testing.csv')\n",
    "\n",
    "#train = pd.read_csv('Datasets/Dataset2_Training.csv')\n",
    "#test = pd.read_csv('Datasets/Dataset2_Testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(train, test):\n",
    "    label_encoder = LabelEncoder().fit(train.species)\n",
    "    labels = label_encoder.transform(train.species)\n",
    "    classes = list(label_encoder.classes_)\n",
    "\n",
    "    train = train.drop(['species', 'id'], axis=1)\n",
    "    test_ids=test.id\n",
    "    test = test.drop('id', axis=1)\n",
    "\n",
    "    return train, labels, test, classes,test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, labels, test, classes,test_ids = encode(train, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# standardize train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(train.values)\n",
    "scaled_train = scaler.transform(train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split train data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(test_size=0.1, random_state=23)\n",
    "for train_index, valid_index in sss.split(scaled_train, labels):\n",
    "    X_train, X_valid = scaled_train[train_index], scaled_train[valid_index]\n",
    "    y_train, y_valid = labels[train_index], labels[valid_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_features = 64 # number of features per features type (shape, texture, margin)   \n",
    "nb_class = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape train data\n",
    "X_train_r = np.zeros((len(X_train), nb_features, 3))\n",
    "X_train_r[:, :, 0] = X_train[:, :nb_features]\n",
    "X_train_r[:, :, 1] = X_train[:, nb_features:128]\n",
    "X_train_r[:, :, 2] = X_train[:, 128:]\n",
    "\n",
    "# reshape validation data\n",
    "X_valid_r = np.zeros((len(X_valid), nb_features, 3))\n",
    "X_valid_r[:, :, 0] = X_valid[:, :nb_features]\n",
    "X_valid_r[:, :, 1] = X_valid[:, nb_features:128]\n",
    "X_valid_r[:, :, 2] = X_valid[:, 128:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timer \n",
    "\n",
    "# Utility custom contextual class for calculating \n",
    "# the time taken for a certain code block to execute\n",
    "    \n",
    "class CodeTimer:\n",
    "    \n",
    "    def __init__(self, name=None):\n",
    "        self.name = \" '\"  + name + \"'\" if name else ''\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time.perf_counter()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.took = (time.perf_counter() - self.start) * 1000.0\n",
    "        time_taken = datetime.timedelta(milliseconds = self.took)\n",
    "        print('Code block' + self.name + ' took(HH:MM:SS): ' + str(time_taken))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 19:59:41.895376: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Keras model with one Convolution1D layer\n",
    "# unfortunately more number of covnolutional layers, filters and filters lenght \n",
    "# don't give better accuracy\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(512, 1, input_shape=(nb_features, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(nb_class))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muneerahmohammad/opt/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "2022-11-07 19:59:43.866176: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "90/90 [==============================] - 26s 283ms/step - loss: 2.9094 - accuracy: 0.3579 - val_loss: 1.0829 - val_accuracy: 0.7250\n",
      "Epoch 2/15\n",
      "90/90 [==============================] - 25s 278ms/step - loss: 0.5410 - accuracy: 0.8589 - val_loss: 0.4052 - val_accuracy: 0.8875\n",
      "Epoch 3/15\n",
      "90/90 [==============================] - 25s 281ms/step - loss: 0.2103 - accuracy: 0.9395 - val_loss: 0.3779 - val_accuracy: 0.8938\n",
      "Epoch 4/15\n",
      "90/90 [==============================] - 25s 282ms/step - loss: 0.1230 - accuracy: 0.9694 - val_loss: 0.2857 - val_accuracy: 0.9375\n",
      "Epoch 5/15\n",
      "90/90 [==============================] - 25s 280ms/step - loss: 0.0749 - accuracy: 0.9792 - val_loss: 0.2452 - val_accuracy: 0.9312\n",
      "Epoch 6/15\n",
      "90/90 [==============================] - 26s 290ms/step - loss: 0.0155 - accuracy: 0.9979 - val_loss: 0.2274 - val_accuracy: 0.9312\n",
      "Epoch 7/15\n",
      "90/90 [==============================] - 26s 286ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.2024 - val_accuracy: 0.9375\n",
      "Epoch 8/15\n",
      "90/90 [==============================] - 26s 291ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9375\n",
      "Epoch 9/15\n",
      "90/90 [==============================] - 26s 292ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9375\n",
      "Epoch 10/15\n",
      "90/90 [==============================] - 26s 285ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9375\n",
      "Epoch 11/15\n",
      "90/90 [==============================] - 26s 291ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9375\n",
      "Epoch 12/15\n",
      "90/90 [==============================] - 25s 282ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9375\n",
      "Epoch 13/15\n",
      "90/90 [==============================] - 25s 283ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9375\n",
      "Epoch 14/15\n",
      "90/90 [==============================] - 26s 287ms/step - loss: 9.7404e-04 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9375\n",
      "Epoch 15/15\n",
      "90/90 [==============================] - 26s 287ms/step - loss: 9.6224e-04 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9375\n",
      "Code block 'training' took(HH:MM:SS): 0:06:25.637158\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_class)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_class)\n",
    "\n",
    "sgd = SGD(lr=0.01, nesterov=True, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "# define an object for training timer\n",
    "training_timer = CodeTimer('training')\n",
    "\n",
    "nb_epoch = 15\n",
    "# calculate training time\n",
    "with training_timer:\n",
    "    model.fit(X_train_r, y_train, epochs=nb_epoch, validation_data=(X_valid_r, y_valid), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(test.values)\n",
    "scaled_test = scaler.transform(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = np.zeros((len(scaled_test), nb_features, 3))\n",
    "test_dataset[:, :, 0] = scaled_test[:, :nb_features]\n",
    "test_dataset[:, :, 1] = scaled_test[:, nb_features:128]\n",
    "test_dataset[:, :, 2] = scaled_test[:, 128:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code block 'testing' took(HH:MM:SS): 0:00:00.260288\n"
     ]
    }
   ],
   "source": [
    "# define an object for testing timer \n",
    "testing_timer = CodeTimer('testing')\n",
    "\n",
    "# calculate testing time\n",
    "with testing_timer:\n",
    "    preds_test = model.predict(test_dataset)\n",
    "    preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Acer_Capillipes</th>\n",
       "      <th>Acer_Circinatum</th>\n",
       "      <th>Acer_Mono</th>\n",
       "      <th>Acer_Opalus</th>\n",
       "      <th>Acer_Palmatum</th>\n",
       "      <th>Acer_Pictum</th>\n",
       "      <th>Acer_Platanoids</th>\n",
       "      <th>Acer_Rubrum</th>\n",
       "      <th>Acer_Rufinerve</th>\n",
       "      <th>...</th>\n",
       "      <th>Salix_Fragilis</th>\n",
       "      <th>Salix_Intergra</th>\n",
       "      <th>Sorbus_Aria</th>\n",
       "      <th>Tilia_Oliveri</th>\n",
       "      <th>Tilia_Platyphyllos</th>\n",
       "      <th>Tilia_Tomentosa</th>\n",
       "      <th>Ulmus_Bergmanniana</th>\n",
       "      <th>Viburnum_Tinus</th>\n",
       "      <th>Viburnum_x_Rhytidophylloides</th>\n",
       "      <th>Zelkova_Serrata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4.627868e-08</td>\n",
       "      <td>6.634896e-08</td>\n",
       "      <td>3.522151e-10</td>\n",
       "      <td>1.979945e-07</td>\n",
       "      <td>5.803275e-08</td>\n",
       "      <td>1.861704e-07</td>\n",
       "      <td>1.154325e-08</td>\n",
       "      <td>6.933443e-09</td>\n",
       "      <td>2.948224e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>9.980554e-10</td>\n",
       "      <td>2.880373e-08</td>\n",
       "      <td>1.176069e-08</td>\n",
       "      <td>1.781970e-09</td>\n",
       "      <td>1.447084e-07</td>\n",
       "      <td>2.871864e-09</td>\n",
       "      <td>1.111443e-08</td>\n",
       "      <td>2.241541e-10</td>\n",
       "      <td>2.935469e-07</td>\n",
       "      <td>1.674585e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>7.428685e-09</td>\n",
       "      <td>2.938926e-08</td>\n",
       "      <td>7.177974e-08</td>\n",
       "      <td>2.458765e-05</td>\n",
       "      <td>1.037744e-09</td>\n",
       "      <td>5.196398e-08</td>\n",
       "      <td>3.845309e-05</td>\n",
       "      <td>9.520064e-09</td>\n",
       "      <td>2.419575e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>9.030985e-09</td>\n",
       "      <td>4.874698e-08</td>\n",
       "      <td>7.610932e-09</td>\n",
       "      <td>1.237863e-10</td>\n",
       "      <td>7.649972e-11</td>\n",
       "      <td>7.480708e-06</td>\n",
       "      <td>2.197336e-09</td>\n",
       "      <td>1.024054e-06</td>\n",
       "      <td>2.632089e-09</td>\n",
       "      <td>3.450862e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>8.191396e-08</td>\n",
       "      <td>9.985400e-01</td>\n",
       "      <td>1.399405e-09</td>\n",
       "      <td>3.588255e-08</td>\n",
       "      <td>1.199303e-04</td>\n",
       "      <td>4.966346e-07</td>\n",
       "      <td>1.305243e-08</td>\n",
       "      <td>6.328683e-07</td>\n",
       "      <td>2.961180e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.644425e-07</td>\n",
       "      <td>6.634397e-10</td>\n",
       "      <td>3.506502e-09</td>\n",
       "      <td>1.220369e-08</td>\n",
       "      <td>2.954225e-08</td>\n",
       "      <td>1.629953e-07</td>\n",
       "      <td>2.807964e-07</td>\n",
       "      <td>2.491332e-10</td>\n",
       "      <td>2.232702e-09</td>\n",
       "      <td>4.196976e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>1.150263e-06</td>\n",
       "      <td>2.886420e-02</td>\n",
       "      <td>8.764577e-08</td>\n",
       "      <td>1.001434e-06</td>\n",
       "      <td>1.765437e-07</td>\n",
       "      <td>5.787755e-07</td>\n",
       "      <td>1.526826e-04</td>\n",
       "      <td>2.277724e-06</td>\n",
       "      <td>6.339775e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>4.053422e-07</td>\n",
       "      <td>3.576528e-09</td>\n",
       "      <td>2.353166e-06</td>\n",
       "      <td>8.379025e-08</td>\n",
       "      <td>3.034356e-07</td>\n",
       "      <td>9.784295e-05</td>\n",
       "      <td>2.959457e-03</td>\n",
       "      <td>2.460465e-08</td>\n",
       "      <td>9.947771e-07</td>\n",
       "      <td>3.574744e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1.502209e-08</td>\n",
       "      <td>1.522091e-07</td>\n",
       "      <td>3.322889e-12</td>\n",
       "      <td>8.429778e-10</td>\n",
       "      <td>4.163709e-10</td>\n",
       "      <td>1.364373e-10</td>\n",
       "      <td>1.179851e-08</td>\n",
       "      <td>9.494687e-09</td>\n",
       "      <td>1.127881e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.750842e-08</td>\n",
       "      <td>2.094141e-12</td>\n",
       "      <td>1.332169e-08</td>\n",
       "      <td>3.254024e-11</td>\n",
       "      <td>4.863334e-07</td>\n",
       "      <td>2.077794e-07</td>\n",
       "      <td>2.510697e-06</td>\n",
       "      <td>1.644894e-10</td>\n",
       "      <td>4.989625e-09</td>\n",
       "      <td>2.808493e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>1576</td>\n",
       "      <td>1.980781e-07</td>\n",
       "      <td>9.992300e-01</td>\n",
       "      <td>1.377305e-09</td>\n",
       "      <td>2.480634e-08</td>\n",
       "      <td>1.132538e-05</td>\n",
       "      <td>1.153638e-07</td>\n",
       "      <td>5.831625e-09</td>\n",
       "      <td>2.102547e-07</td>\n",
       "      <td>1.737823e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027708e-07</td>\n",
       "      <td>4.041034e-10</td>\n",
       "      <td>5.084368e-09</td>\n",
       "      <td>4.577399e-09</td>\n",
       "      <td>1.080938e-08</td>\n",
       "      <td>2.070408e-07</td>\n",
       "      <td>1.218631e-06</td>\n",
       "      <td>2.544389e-10</td>\n",
       "      <td>5.468262e-09</td>\n",
       "      <td>2.023965e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>1577</td>\n",
       "      <td>4.944513e-06</td>\n",
       "      <td>2.319805e-07</td>\n",
       "      <td>1.970380e-09</td>\n",
       "      <td>6.093211e-06</td>\n",
       "      <td>9.794660e-09</td>\n",
       "      <td>7.245751e-09</td>\n",
       "      <td>8.901698e-07</td>\n",
       "      <td>2.040376e-06</td>\n",
       "      <td>1.286026e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.959674e-07</td>\n",
       "      <td>2.953459e-09</td>\n",
       "      <td>4.644566e-05</td>\n",
       "      <td>1.333897e-07</td>\n",
       "      <td>7.473868e-05</td>\n",
       "      <td>8.508134e-05</td>\n",
       "      <td>1.242911e-06</td>\n",
       "      <td>4.974089e-09</td>\n",
       "      <td>1.714420e-07</td>\n",
       "      <td>3.797790e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>1579</td>\n",
       "      <td>1.505680e-06</td>\n",
       "      <td>1.657436e-07</td>\n",
       "      <td>2.288140e-09</td>\n",
       "      <td>9.277619e-10</td>\n",
       "      <td>9.284466e-07</td>\n",
       "      <td>1.009479e-06</td>\n",
       "      <td>1.357591e-08</td>\n",
       "      <td>4.307246e-08</td>\n",
       "      <td>1.059829e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.816050e-10</td>\n",
       "      <td>1.863703e-10</td>\n",
       "      <td>2.407928e-07</td>\n",
       "      <td>7.499912e-07</td>\n",
       "      <td>9.411053e-07</td>\n",
       "      <td>2.690780e-10</td>\n",
       "      <td>1.739623e-09</td>\n",
       "      <td>2.757382e-09</td>\n",
       "      <td>1.663812e-07</td>\n",
       "      <td>1.342949e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>1580</td>\n",
       "      <td>1.126535e-11</td>\n",
       "      <td>1.447198e-10</td>\n",
       "      <td>2.062197e-08</td>\n",
       "      <td>1.178442e-09</td>\n",
       "      <td>2.203069e-09</td>\n",
       "      <td>2.306448e-11</td>\n",
       "      <td>8.678703e-10</td>\n",
       "      <td>1.264675e-08</td>\n",
       "      <td>3.107717e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>6.001701e-09</td>\n",
       "      <td>8.752934e-09</td>\n",
       "      <td>6.873060e-13</td>\n",
       "      <td>7.803693e-09</td>\n",
       "      <td>3.993096e-12</td>\n",
       "      <td>1.915356e-09</td>\n",
       "      <td>9.416861e-12</td>\n",
       "      <td>1.363226e-09</td>\n",
       "      <td>3.964289e-12</td>\n",
       "      <td>1.397565e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>1583</td>\n",
       "      <td>2.770167e-08</td>\n",
       "      <td>1.691772e-07</td>\n",
       "      <td>4.089829e-07</td>\n",
       "      <td>4.408235e-09</td>\n",
       "      <td>1.030430e-07</td>\n",
       "      <td>5.876014e-05</td>\n",
       "      <td>2.785166e-06</td>\n",
       "      <td>3.021672e-08</td>\n",
       "      <td>4.666464e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.451079e-07</td>\n",
       "      <td>2.431035e-08</td>\n",
       "      <td>4.242652e-08</td>\n",
       "      <td>5.160824e-08</td>\n",
       "      <td>2.039157e-07</td>\n",
       "      <td>1.517972e-07</td>\n",
       "      <td>2.152829e-08</td>\n",
       "      <td>1.689181e-07</td>\n",
       "      <td>3.873313e-09</td>\n",
       "      <td>8.806063e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  Acer_Capillipes  Acer_Circinatum     Acer_Mono   Acer_Opalus  \\\n",
       "0       4     4.627868e-08     6.634896e-08  3.522151e-10  1.979945e-07   \n",
       "1       7     7.428685e-09     2.938926e-08  7.177974e-08  2.458765e-05   \n",
       "2       9     8.191396e-08     9.985400e-01  1.399405e-09  3.588255e-08   \n",
       "3      12     1.150263e-06     2.886420e-02  8.764577e-08  1.001434e-06   \n",
       "4      13     1.502209e-08     1.522091e-07  3.322889e-12  8.429778e-10   \n",
       "..    ...              ...              ...           ...           ...   \n",
       "589  1576     1.980781e-07     9.992300e-01  1.377305e-09  2.480634e-08   \n",
       "590  1577     4.944513e-06     2.319805e-07  1.970380e-09  6.093211e-06   \n",
       "591  1579     1.505680e-06     1.657436e-07  2.288140e-09  9.277619e-10   \n",
       "592  1580     1.126535e-11     1.447198e-10  2.062197e-08  1.178442e-09   \n",
       "593  1583     2.770167e-08     1.691772e-07  4.089829e-07  4.408235e-09   \n",
       "\n",
       "     Acer_Palmatum   Acer_Pictum  Acer_Platanoids   Acer_Rubrum  \\\n",
       "0     5.803275e-08  1.861704e-07     1.154325e-08  6.933443e-09   \n",
       "1     1.037744e-09  5.196398e-08     3.845309e-05  9.520064e-09   \n",
       "2     1.199303e-04  4.966346e-07     1.305243e-08  6.328683e-07   \n",
       "3     1.765437e-07  5.787755e-07     1.526826e-04  2.277724e-06   \n",
       "4     4.163709e-10  1.364373e-10     1.179851e-08  9.494687e-09   \n",
       "..             ...           ...              ...           ...   \n",
       "589   1.132538e-05  1.153638e-07     5.831625e-09  2.102547e-07   \n",
       "590   9.794660e-09  7.245751e-09     8.901698e-07  2.040376e-06   \n",
       "591   9.284466e-07  1.009479e-06     1.357591e-08  4.307246e-08   \n",
       "592   2.203069e-09  2.306448e-11     8.678703e-10  1.264675e-08   \n",
       "593   1.030430e-07  5.876014e-05     2.785166e-06  3.021672e-08   \n",
       "\n",
       "     Acer_Rufinerve  ...  Salix_Fragilis  Salix_Intergra   Sorbus_Aria  \\\n",
       "0      2.948224e-08  ...    9.980554e-10    2.880373e-08  1.176069e-08   \n",
       "1      2.419575e-08  ...    9.030985e-09    4.874698e-08  7.610932e-09   \n",
       "2      2.961180e-05  ...    1.644425e-07    6.634397e-10  3.506502e-09   \n",
       "3      6.339775e-05  ...    4.053422e-07    3.576528e-09  2.353166e-06   \n",
       "4      1.127881e-05  ...    1.750842e-08    2.094141e-12  1.332169e-08   \n",
       "..              ...  ...             ...             ...           ...   \n",
       "589    1.737823e-05  ...    1.027708e-07    4.041034e-10  5.084368e-09   \n",
       "590    1.286026e-04  ...    1.959674e-07    2.953459e-09  4.644566e-05   \n",
       "591    1.059829e-08  ...    1.816050e-10    1.863703e-10  2.407928e-07   \n",
       "592    3.107717e-11  ...    6.001701e-09    8.752934e-09  6.873060e-13   \n",
       "593    4.666464e-08  ...    1.451079e-07    2.431035e-08  4.242652e-08   \n",
       "\n",
       "     Tilia_Oliveri  Tilia_Platyphyllos  Tilia_Tomentosa  Ulmus_Bergmanniana  \\\n",
       "0     1.781970e-09        1.447084e-07     2.871864e-09        1.111443e-08   \n",
       "1     1.237863e-10        7.649972e-11     7.480708e-06        2.197336e-09   \n",
       "2     1.220369e-08        2.954225e-08     1.629953e-07        2.807964e-07   \n",
       "3     8.379025e-08        3.034356e-07     9.784295e-05        2.959457e-03   \n",
       "4     3.254024e-11        4.863334e-07     2.077794e-07        2.510697e-06   \n",
       "..             ...                 ...              ...                 ...   \n",
       "589   4.577399e-09        1.080938e-08     2.070408e-07        1.218631e-06   \n",
       "590   1.333897e-07        7.473868e-05     8.508134e-05        1.242911e-06   \n",
       "591   7.499912e-07        9.411053e-07     2.690780e-10        1.739623e-09   \n",
       "592   7.803693e-09        3.993096e-12     1.915356e-09        9.416861e-12   \n",
       "593   5.160824e-08        2.039157e-07     1.517972e-07        2.152829e-08   \n",
       "\n",
       "     Viburnum_Tinus  Viburnum_x_Rhytidophylloides  Zelkova_Serrata  \n",
       "0      2.241541e-10                  2.935469e-07     1.674585e-08  \n",
       "1      1.024054e-06                  2.632089e-09     3.450862e-08  \n",
       "2      2.491332e-10                  2.232702e-09     4.196976e-04  \n",
       "3      2.460465e-08                  9.947771e-07     3.574744e-03  \n",
       "4      1.644894e-10                  4.989625e-09     2.808493e-09  \n",
       "..              ...                           ...              ...  \n",
       "589    2.544389e-10                  5.468262e-09     2.023965e-04  \n",
       "590    4.974089e-09                  1.714420e-07     3.797790e-05  \n",
       "591    2.757382e-09                  1.663812e-07     1.342949e-06  \n",
       "592    1.363226e-09                  3.964289e-12     1.397565e-09  \n",
       "593    1.689181e-07                  3.873313e-09     8.806063e-07  \n",
       "\n",
       "[594 rows x 100 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(preds_test, columns=classes)\n",
    "submission.insert(0, 'id', test_ids)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "submission.to_csv('Resultsubmission.csv', index=False)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
